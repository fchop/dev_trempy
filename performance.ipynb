{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import norm\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trempy.read.read import read\n",
    "from trempy.clsModel import ModelCls\n",
    "from trempy.process.process import process\n",
    "from trempy.shared.shared_auxiliary import dist_class_attributes\n",
    "from trempy.shared.shared_auxiliary import get_optimal_compensations\n",
    "from trempy.config_trempy import NEVER_SWITCHERS\n",
    "from trempy.config_trempy import TINY_FLOAT\n",
    "from trempy.config_trempy import HUGE_FLOAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'performance/start.trempy.ini'\n",
    "model_obj = ModelCls(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "# Distribute class parameters except for economic parameters and version-specific thing\n",
    "args = [model_obj, 'version', 'est_file', 'questions', 'paras_obj', 'start', 'cutoffs',\n",
    "        'maxfun', 'est_detailed', 'opt_options', 'optimizer', 'est_agents', 'num_skip']\n",
    "\n",
    "version, est_file, questions, paras_obj, start, cutoffs, maxfun, est_detailed, \\\n",
    "    opt_options, optimizer, est_agents, num_skip = dist_class_attributes(*args)\n",
    "\n",
    "# Handle version-specific objects not included in the para_obj\n",
    "if version in ['scaled_archimedean']:\n",
    "    upper, marginals = dist_class_attributes(*[model_obj, 'upper', 'marginals'])\n",
    "    version_specific = {'upper': upper, 'marginals': marginals}\n",
    "elif version in ['nonstationary']:\n",
    "    version_specific = dict()\n",
    "\n",
    "# We only need to continue if there is at least one parameter to actually estimate.\n",
    "if len(paras_obj.get_values('optim', 'free')) == 0:\n",
    "    raise TrempyError('no free parameter to estimate')\n",
    "\n",
    "# Some initial setup\n",
    "df_obs = process(est_file, questions, num_skip, est_agents, cutoffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criterium function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ORIGINAL FUNCTION!\n",
    "def criterion_function(df, questions, cutoffs, paras_obj, version, sds, **version_specific):\n",
    "    \"\"\"Calculate the likelihood of the observed sample.\n",
    "\n",
    "    sds: standard deviations for each question.\n",
    "    model_obj: the ModelCls object\n",
    "    version: nonstationary or scaled_archimedean\n",
    "    \"\"\"\n",
    "    # Distribute parameters\n",
    "    m_optimal = get_optimal_compensations(version=version, paras_obj=paras_obj, questions=questions,\n",
    "                                          **version_specific)\n",
    "\n",
    "    contribs = []\n",
    "    for i, q in enumerate(questions):\n",
    "        df_subset = df.loc[(slice(None), q), \"Compensation\"].copy().to_frame('Compensation')\n",
    "        lower, upper = cutoffs[q]\n",
    "\n",
    "        is_not = df_subset['Compensation'].between(lower, upper, inclusive=False)\n",
    "        is_upper = df_subset['Compensation'].isin([NEVER_SWITCHERS])\n",
    "        is_lower = df_subset['Compensation'].isin([lower])\n",
    "\n",
    "        rv = norm(loc=m_optimal[q], scale=sds[i])\n",
    "\n",
    "        # Calculate likelihoods\n",
    "        df_subset['likl_not'] = np.nan\n",
    "        df_subset['likl_not'] = df_subset['likl_not'].mask(~is_not)\n",
    "\n",
    "        df_subset['likl_not'].loc[is_not, :] = rv.pdf(df_subset['Compensation'].loc[is_not, :])\n",
    "        df_subset['likl_upper'] = 1.0 - rv.cdf(upper)\n",
    "        df_subset['likl_lower'] = rv.cdf(lower)\n",
    "\n",
    "        df_subset['likl'] = 0.0\n",
    "        df_subset['likl'][is_upper] = df_subset['likl_upper'].loc[is_upper]\n",
    "        df_subset['likl'][is_lower] = df_subset['likl_lower'].loc[is_lower]\n",
    "        df_subset['likl'][is_not] = df_subset['likl_not'].loc[is_not]\n",
    "\n",
    "        contribs += df_subset['likl'].values.tolist()\n",
    "\n",
    "    rslt = -np.mean(np.log(np.clip(sorted(contribs), TINY_FLOAT, np.inf)))\n",
    "\n",
    "    return rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_function_2(df, questions, cutoffs, paras_obj, version, sds, **version_specific):\n",
    "    \"\"\"Calculate the likelihood of the observed sample.\n",
    "\n",
    "    sds: standard deviations for each question.\n",
    "    model_obj: the ModelCls object\n",
    "    version: nonstationary or scaled_archimedean\n",
    "    \"\"\"\n",
    "    # Distribute parameters\n",
    "    m_optimal = get_optimal_compensations(version=version, paras_obj=paras_obj, questions=questions,\n",
    "                                          **version_specific)\n",
    "\n",
    "    contribs = []\n",
    "    for i, q in enumerate(questions):\n",
    "        df_subset = df.loc[(slice(None), q), \"Compensation\"].copy().to_frame('Compensation')\n",
    "        lower, upper = cutoffs[q]\n",
    "\n",
    "        is_not = df_subset['Compensation'].between(lower, upper, inclusive=False)\n",
    "        is_upper = df_subset['Compensation'].isin([NEVER_SWITCHERS])\n",
    "        is_lower = ~(is_not | is_upper)\n",
    "\n",
    "        rv = norm(loc=m_optimal[q], scale=sds[i])\n",
    "\n",
    "        # Calculate likelihoods\n",
    "        df_subset['likl_not'] = rv.pdf(df_subset['Compensation'])\n",
    "        df_subset['likl_upper'] = 1.0 - rv.cdf(upper)\n",
    "        df_subset['likl_lower'] = rv.cdf(lower)\n",
    "\n",
    "        \n",
    "        likl_upper = df_subset['likl_upper'].loc[is_upper, :]\n",
    "        likl_lower = df_subset['likl_lower'].loc[is_lower, :]\n",
    "        likl_interior = df_subset['likl_not'].loc[is_not, :]\n",
    "\n",
    "        contribs += likl_upper.values.tolist()\n",
    "        contribs += likl_lower.values.tolist()\n",
    "        contribs += likl_interior.values.tolist()\n",
    "\n",
    "    rslt = -np.mean(np.log(np.clip(sorted(contribs), TINY_FLOAT, np.inf)))\n",
    "\n",
    "    return rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct relevant set of parameters\n",
    "x_econ_all_current = paras_obj.get_values('econ', 'all')\n",
    "\n",
    "# Get standard deviations. They have a larger index than nparas_econ.\n",
    "nparas_econ = paras_obj.attr['nparas_econ']\n",
    "stands = x_econ_all_current[nparas_econ:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.39 s ± 83.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit criterion_function(df_obs, questions, cutoffs, paras_obj, version, stands, **version_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.531515655563092"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_function(df_obs, questions, cutoffs, paras_obj, version, stands, **version_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.554537304763064"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_function_2(df_obs, questions, cutoffs, paras_obj, version, stands, **version_specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvements\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_function_new(df, questions, cutoffs, paras_obj, version, sds, **version_specific):\n",
    "    \"\"\"Calculate the likelihood of the observed sample.\"\"\"\n",
    "\n",
    "    m_optimal = get_optimal_compensations(\n",
    "        version=version, paras_obj=paras_obj, questions=questions, **version_specific)\n",
    "    data = copy.deepcopy(df)\n",
    "    \n",
    "    # Add cutoff column\n",
    "    df_cutoff = pd.DataFrame.from_dict(cutoffs, orient='index', columns=['lower', 'upper'])\n",
    "    df_cutoff = df_cutoff.reset_index()\n",
    "    df_cutoff = df_cutoff.rename(columns={'index': 'Question'})\n",
    "    data = data.reset_index()\n",
    "    data = data.merge(df_cutoff, how='left', on='Question')\n",
    "\n",
    "    # Add indicator for interior/boundary choices.\n",
    "    data['is_interior'] = (data.lower < data.Compensation) & (data.Compensation < data.upper)\n",
    "    data['is_upper'] = data['Compensation'].isin([NEVER_SWITCHERS])\n",
    "    data['is_lower'] = ~(data.is_interior | data.is_upper)\n",
    "\n",
    "    # Add column with the theortically optimal decision for each question\n",
    "    df_m_optimal = pd.DataFrame.from_dict(m_optimal, orient='index', columns=['m_optim'])\n",
    "    df_m_optimal = df_m_optimal.reset_index().rename(columns={'index': 'Question'})\n",
    "    data = data.merge(df_m_optimal, how='left', on='Question')\n",
    "\n",
    "    # Add column with standard deviation of the implementation error for each question\n",
    "    df_std = pd.DataFrame(sds, index=questions, columns=['std'])\n",
    "    df_std = df_std.reset_index().rename(columns={'index': 'Question'})\n",
    "    data = data.merge(df_std, how='left', on='Question')\n",
    "    \n",
    "    # Debugging. Delete later.\n",
    "    np.testing.assert_equal(data.isna().sum().sum() == 0, True)\n",
    "    np.testing.assert_equal(data.shape[0] == df.shape[0], True)\n",
    "    \n",
    "    # Add standardized choices\n",
    "    data['choice_standardized'] = (data['Compensation'] - data['m_optim']) / data['std']\n",
    "    data['lower_standardized'] = (data['lower'] - data['m_optim']) / data['std']\n",
    "    data['upper_standardized'] = (data['upper'] - data['m_optim']) / data['std']\n",
    "\n",
    "    # We only need the standard normal distribution for standardized choices.\n",
    "    rv = norm(loc=0.0, scale=1.0)\n",
    "\n",
    "    # Compute likelihood of each question-subject pair based on interior/boundary status.\n",
    "    likl_interior = (rv.pdf(data['choice_standardized'].loc[data['is_interior']]) /\n",
    "                     data['std'].loc[data['is_interior']])\n",
    "    \n",
    "    likl_upper = 1.0 - rv.cdf(data['upper_standardized'].loc[data['is_upper']])\n",
    "    likl_lower = rv.cdf(data['lower_standardized'].loc[data['is_lower']])\n",
    "    \n",
    "    # Add all summands to one list.\n",
    "    contribs = likl_interior.tolist() + likl_lower.tolist() + likl_upper.tolist()\n",
    "        \n",
    "    # Compute the average negative log-likelihood\n",
    "    rslt = - np.mean(np.log(np.clip(sorted(contribs), TINY_FLOAT, np.inf)))\n",
    "\n",
    "    return rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.554537304763064"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_function_new(df_obs, questions, cutoffs, paras_obj, version, stands, **version_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370 ms ± 17.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit criterion_function_new(df_obs, questions, cutoffs, paras_obj, version, stands, **version_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
